"""
Gemini AI ì„œë¹„ìŠ¤ - ìì—°ì–´ ì²˜ë¦¬ ë° ê´€ê´‘ì§€ ì¶”ì²œ
"""
import logging
import json
from typing import List, Dict, Optional
from django.conf import settings
import google.generativeai as genai
# Django ëª¨ë¸ ì œê±° - Firestore ê¸°ë°˜ìœ¼ë¡œ ì „í™˜
# from tourism.models import TourismSpot
# from tourism.services import TourismDataService

logger = logging.getLogger(__name__)

class GeminiAIService:
    """Gemini AIë¥¼ ì´ìš©í•œ ìì—°ì–´ ì²˜ë¦¬ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        try:
            if settings.GEMINI_API_KEY:
                genai.configure(api_key=settings.GEMINI_API_KEY)
                
                # System instruction ì„¤ì •
                system_instruction = """
                ë‹¹ì‹ ì€ ê²½ìƒë¶ë„ ì˜ì„±êµ° ê´€ê´‘ì§€ ì¶”ì²œ ì „ë¬¸ AIì…ë‹ˆë‹¤.
                
                ì£¼ìš” ì—­í• :
                1. ì‚¬ìš©ìì˜ ìì—°ì–´ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ê´€ê´‘ì§€ë¥¼ ì¶”ì²œ
                2. ì˜ì„±êµ°ì˜ íŠ¹ìƒ‰ê³¼ ë¬¸í™”ë¥¼ ë°˜ì˜í•œ ì¶”ì²œ ì œê³µ
                3. ì •í™•í•˜ê³  ìœ ìš©í•œ ê´€ê´‘ ì •ë³´ ì œê³µ
                
                ì˜ì„±êµ° ì£¼ìš” íŠ¹ì§•:
                - ë§ˆëŠ˜ê³¼ ì–‘íŒŒì˜ ê³ ì¥ìœ¼ë¡œ ìœ ëª…
                - ì¡°ë¬¸êµ­ ìœ ì ì§€ì™€ ì—­ì‚¬ ë¬¸í™”ì¬ ë³´ìœ 
                - ë¹™ê³„ê³„ê³¡, ì‚¬ì´Œì—­ ì€í–‰ë‚˜ë¬´ ë“± ìì—° ê´€ê´‘ì§€
                - ì „í†µê³¼ í˜„ëŒ€ê°€ ì¡°í™”ëœ ê´€ê´‘ ë„ì‹œ
                
                ì‘ë‹µ ì›ì¹™:
                - í•­ìƒ JSON í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ë°ì´í„° ì œê³µ
                - JSON ì…ë ¥ì˜ key ìˆœì„œëŠ” ì ˆëŒ€ ë°”ê¾¸ì§€ ì•ŠìŠµë‹ˆë‹¤
                - ìŒì‹ì , ìˆ™ë°•, ê´€ê´‘ì§€ëŠ” ê°ê° ìµœì†Œ 5ê°œ ì´ìƒ ì¶”ì²œ

                """
                
                self.model = genai.GenerativeModel(
                    'gemini-2.5-flash',
                    system_instruction=system_instruction
                )
                logger.info("Gemini AI initialized successfully with gemini-2.5-flash and system instruction")
            else:
                logger.error("GEMINI_API_KEY not found in settings")
                self.model = None
        except Exception as e:
            logger.error(f"Failed to initialize Gemini AI: {e}")
            self.model = None
        
        # Django ëª¨ë¸ ì œê±° - Firestore ì§ì ‘ ì‚¬ìš©
        # self.tourism_service = TourismDataService()
    
    def analyze_user_query(self, user_query: str) -> Dict:
        """ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ê´€ê´‘ì§€ ê²€ìƒ‰ ì¡°ê±´ ì¶”ì¶œ"""
        try:
            # Gemini AI ìƒíƒœ ìƒì„¸ ë¡œê¹…
            logger.info(f"=== Gemini AI ìƒíƒœ í™•ì¸ ===")
            logger.info(f"self.model ì¡´ì¬: {self.model is not None}")
            logger.info(f"GEMINI_API_KEY ì„¤ì •: {bool(getattr(settings, 'GEMINI_API_KEY', None))}")
            
            if not self.model:
                logger.warning("âš ï¸ Gemini AI not available, using fallback analysis")
                logger.warning("Gemini AIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ í´ë°± ë¶„ì„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤")
                return self._fallback_analysis(user_query)
            
            logger.info("âœ… Gemini AI ì‚¬ìš© ê°€ëŠ¥ - ì‹¤ì œ AI ë¶„ì„ ì‹œì‘")
            
            # ì˜ì„±êµ° ê´€ê´‘ì§€ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_analysis_prompt(user_query)
            logger.info(f"Generated prompt length: {len(prompt)}")
            
            logger.info("ğŸ¤– Gemini AI í˜¸ì¶œ ì¤‘...")
            response = self.model.generate_content(prompt)
            logger.info(f"âœ… Gemini AI ì‘ë‹µ ë°›ìŒ: {response.text[:100]}...")
            
            # ì‘ë‹µ íŒŒì‹±
            analysis_result = self._parse_analysis_response(response.text)
            
            logger.info(f"Query analysis completed for: {user_query}")
            logger.info(f"Analysis result: {analysis_result}")
            
            return {
                'success': True,
                'original_query': user_query,
                'analysis': analysis_result,
                'processed_query': analysis_result.get('processed_query', user_query),
                'gemini_used': True  # Geminiê°€ ì‹¤ì œë¡œ ì‚¬ìš©ë˜ì—ˆìŒì„ í‘œì‹œ
            }
            
        except Exception as e:
            logger.error(f"âŒ Error analyzing user query with Gemini: {e}")
            import traceback
            logger.error(f"Gemini ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
            # Gemini ì‹¤íŒ¨ ì‹œ í´ë°± ë¶„ì„ ì‚¬ìš©
            logger.warning("Gemini ì‹¤íŒ¨ë¡œ í´ë°± ë¶„ì„ ì‚¬ìš©")
            return self._fallback_analysis(user_query)
    
    def _fallback_analysis(self, user_query: str) -> Dict:
        """Gemini AIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì„ ë•Œì˜ í´ë°± ë¶„ì„"""
        logger.info("ğŸ”„ í´ë°± ë¶„ì„ ì‹œì‘ (Gemini AI ë¯¸ì‚¬ìš©)")
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„
        keywords = []
        categories = []
        
        # ìì—° ê´€ë ¨ í‚¤ì›Œë“œ
        nature_keywords = ['ìì—°', 'ê²½ê´€', 'ì‚°', 'ê³„ê³¡', 'ê°•', 'í˜¸ìˆ˜', 'ë‚˜ë¬´', 'ìˆ²', 'í’ê²½']
        cultural_keywords = ['ë¬¸í™”', 'ì—­ì‚¬', 'ìœ ì ', 'ë°•ë¬¼ê´€', 'ì „í†µ', 'ê³ íƒ', 'ì‚¬ì°°', 'ì ˆ']
        experience_keywords = ['ì²´í—˜', 'í™œë™', 'ë†€ì´', 'ì¶•ì œ', 'ì´ë²¤íŠ¸']
        
        query_lower = user_query.lower()
        
        for keyword in nature_keywords:
            if keyword in user_query:
                keywords.append(keyword)
                if 'ìì—°ê´€ê´‘ì§€' not in categories:
                    categories.append('ìì—°ê´€ê´‘ì§€')
        
        for keyword in cultural_keywords:
            if keyword in user_query:
                keywords.append(keyword)
                if 'ë¬¸í™”ì¬/ìœ ì ì§€' not in categories:
                    categories.append('ë¬¸í™”ì¬/ìœ ì ì§€')
        
        for keyword in experience_keywords:
            if keyword in user_query:
                keywords.append(keyword)
                if 'ì²´í—˜ê´€ê´‘ì§€' not in categories:
                    categories.append('ì²´í—˜ê´€ê´‘ì§€')
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        if not keywords:
            keywords = ['ê´€ê´‘', 'ì—¬í–‰']
        if not categories:
            categories = ['ì¼ë°˜']
        
        logger.info(f"í´ë°± ë¶„ì„ ê²°ê³¼ - í‚¤ì›Œë“œ: {keywords}, ì¹´í…Œê³ ë¦¬: {categories}")
        
        analysis_result = {
            'keywords': keywords,
            'categories': categories,
            'preferences': [],
            'intent': 'general_search',
            'processed_query': user_query,
            'confidence': 0.7,
            'fallback': True
        }
        
        return {
            'success': True,
            'original_query': user_query,
            'analysis': analysis_result,
            'processed_query': user_query,
            'gemini_used': False  # Geminiê°€ ì‚¬ìš©ë˜ì§€ ì•Šì•˜ìŒì„ í‘œì‹œ
        }
    
    def recommend_tourism_spots(self, user_query: str, max_results: int = 30) -> Dict:
        """ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´€ê´‘ì§€ ì¶”ì²œ"""
        try:
            # 1. ì¿¼ë¦¬ ë¶„ì„
            analysis_result = self.analyze_user_query(user_query)
            
            if not analysis_result['success']:
                return analysis_result
            
            analysis = analysis_result['analysis']
            
            # 2. ê´€ê´‘ì§€ ê²€ìƒ‰
            recommended_spots = []
            
            # í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰
            if analysis.get('keywords'):
                spots = self.tourism_service.search_spots_by_keywords(analysis['keywords'])
                recommended_spots.extend(spots)
            
            # ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ê²€ìƒ‰
            if analysis.get('categories'):
                for category in analysis['categories']:
                    spots = self.tourism_service.get_spots_by_category(category)
                    recommended_spots.extend(spots)
            
            # ì¤‘ë³µ ì œê±°
            unique_spots = list({spot.id: spot for spot in recommended_spots}.values())
            
            # 3. AI ê¸°ë°˜ ì¬ìˆœìœ„ ë§¤ê¸°ê¸°
            if unique_spots and len(unique_spots) > max_results:
                ranked_spots = self._rank_spots_with_ai(user_query, unique_spots, max_results)
            else:
                ranked_spots = unique_spots[:max_results]
            
            # 4. ê²°ê³¼ í¬ë§·íŒ…
            result_data = []
            for spot in ranked_spots:
                result_data.append(spot.to_dict())
            
            return {
                'success': True,
                'query': user_query,
                'analysis': analysis,
                'recommended_spots': result_data,
                'total_found': len(unique_spots),
                'returned_count': len(result_data)
            }
            
        except Exception as e:
            logger.error(f"Error recommending tourism spots: {e}")
            return {'success': False, 'message': str(e)}
    
    def _create_analysis_prompt(self, user_query: str) -> str:
        """ì‚¬ìš©ì ì¿¼ë¦¬ ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""
        ì˜ì„±êµ° ê´€ê´‘ì§€ ì¶”ì²œ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìì—°ì–´ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

        ì‚¬ìš©ì ì¿¼ë¦¬: "{user_query}"

        ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ JSON í˜•íƒœë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:
        {{
            "keywords": ["ì¶”ì¶œëœ í‚¤ì›Œë“œë“¤"],
            "categories": ["ê´€ê´‘ì§€ ì¹´í…Œê³ ë¦¬ë“¤"],
            "preferences": ["ì‚¬ìš©ì ì„ í˜¸ì‚¬í•­ë“¤"],
            "intent": "ì‚¬ìš©ì ì˜ë„",
            "processed_query": "ì •ì œëœ ê²€ìƒ‰ ì¿¼ë¦¬",
            "confidence": 0.0-1.0
        }}

        ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬:
        - ë¬¸í™”ì¬/ìœ ì ì§€
        - ìì—°ê´€ê´‘ì§€
        - ì²´í—˜ê´€ê´‘ì§€
        - ì¶•ì œ/ì´ë²¤íŠ¸
        - ìŒì‹/ë§›ì§‘
        - ìˆ™ë°•ì‹œì„¤
        - ë ˆì €/ìŠ¤í¬ì¸ 

        ì˜ì„±êµ°ì˜ íŠ¹ìƒ‰:
        - ë§ˆëŠ˜ê³¼ ì–‘íŒŒì˜ ê³ ì¥
        - ì¡°ë¬¸êµ­ ìœ ì ì§€
        - ë¹™ê³„ê³„ê³¡
        - ì‚¬ì´Œì—­ ì€í–‰ë‚˜ë¬´
        - ì˜ì„± ì¡°ë¬¸êµ­ì‚¬ì ì§€
        """
    
    def _parse_analysis_response(self, response_text: str) -> Dict:
        """AI ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜"""
        try:
            # JSON ë¶€ë¶„ ì¶”ì¶œ
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            
            if start_idx != -1 and end_idx != -1:
                json_str = response_text[start_idx:end_idx]
                return json.loads(json_str)
            else:
                # JSON í˜•íƒœê°€ ì•„ë‹Œ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
                return {
                    'keywords': [response_text.strip()],
                    'categories': [],
                    'preferences': [],
                    'intent': 'general_search',
                    'processed_query': response_text.strip(),
                    'confidence': 0.5
                }
                
        except json.JSONDecodeError:
            logger.warning(f"Failed to parse AI response as JSON: {response_text}")
            return {
                'keywords': [],
                'categories': [],
                'preferences': [],
                'intent': 'unknown',
                'processed_query': response_text.strip(),
                'confidence': 0.3
            }
    
    def _rank_spots_with_ai(self, user_query: str, spots: List[Dict], max_results: int) -> List[Dict]:
        """AIë¥¼ ì´ìš©í•˜ì—¬ ê´€ê´‘ì§€ ìˆœìœ„ ë§¤ê¸°ê¸°"""
        try:
            if not self.model:
                return spots[:max_results]
            
            # ê´€ê´‘ì§€ ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            spots_info = []
            for i, spot in enumerate(spots):
                spots_info.append(f"{i}: {spot.get('title', '')} - {spot.get('overview', '')} ({spot.get('category', '')})")
            
            prompt = f"""
            ì‚¬ìš©ì ì¿¼ë¦¬: "{user_query}"
            
            ë‹¤ìŒ ê´€ê´‘ì§€ë“¤ ì¤‘ì—ì„œ ì‚¬ìš©ì ì¿¼ë¦¬ì— ê°€ì¥ ì í•©í•œ ìˆœì„œë¡œ {max_results}ê°œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:
            
            {chr(10).join(spots_info)}
            
            ì„ íƒëœ ê´€ê´‘ì§€ì˜ ì¸ë±ìŠ¤ë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë°˜í™˜í•´ì£¼ì„¸ìš” (ì˜ˆ: 0,3,7,12,5):
            """
            
            response = self.model.generate_content(prompt)
            indices_str = response.text.strip()
            
            # ì¸ë±ìŠ¤ íŒŒì‹±
            try:
                indices = [int(idx.strip()) for idx in indices_str.split(',')]
                ranked_spots = [spots[i] for i in indices if 0 <= i < len(spots)]
                return ranked_spots[:max_results]
            except (ValueError, IndexError):
                logger.warning(f"Failed to parse ranking indices: {indices_str}")
                return spots[:max_results]
                
        except Exception as e:
            logger.error(f"Error ranking spots with AI: {e}")
            return spots[:max_results]
    
    def generate_tourism_description(self, spots: List[Dict]) -> str:
        """ì„ íƒëœ ê´€ê´‘ì§€ë“¤ì— ëŒ€í•œ ì¢…í•© ì„¤ëª… ìƒì„±"""
        try:
            if not self.model or not spots:
                return ""
            
            spots_info = []
            for spot in spots:
                spots_info.append(f"- {spot.get('name', '')}: {spot.get('description', '')}")
            
            prompt = f"""
            ë‹¤ìŒ ì˜ì„±êµ° ê´€ê´‘ì§€ë“¤ì— ëŒ€í•œ ë§¤ë ¥ì ì¸ ì—¬í–‰ ì„¤ëª…ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
            
            {chr(10).join(spots_info)}
            
            ìš”êµ¬ì‚¬í•­:
            1. ê° ê´€ê´‘ì§€ì˜ íŠ¹ìƒ‰ì„ ì‚´ë¦° ì„¤ëª…
            2. ì˜ì„±êµ°ì˜ ì§€ì—­ íŠ¹ìƒ‰ í¬í•¨
            3. ë°©ë¬¸ê°ë“¤ì´ í¥ë¯¸ë¥¼ ëŠë‚„ ìˆ˜ ìˆëŠ” ë‚´ìš©
            4. 200-300ì ë‚´ì™¸
            """
            
            response = self.model.generate_content(prompt)
            return response.text.strip()
            
        except Exception as e:
            logger.error(f"Error generating tourism description: {e}")
            return ""
    
    def recommend_tourism_spots(self, user_query: str, all_spots: List[Dict]) -> Dict:
        """ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´€ê´‘ì§€ ì¶”ì²œ"""
        try:
            # 1. ì‚¬ìš©ì ì¿¼ë¦¬ ë¶„ì„
            analysis_result = self.analyze_user_query(user_query)
            
            if not analysis_result.get('success'):
                return {
                    'success': False,
                    'message': 'ì¿¼ë¦¬ ë¶„ì„ ì‹¤íŒ¨',
                    'analysis': {},
                    'recommended_spots': []
                }
            
            analysis = analysis_result.get('analysis', {})
            
            # 2. ê´€ê´‘ì§€ í•„í„°ë§ ë° ìˆœìœ„ ë§¤ê¸°ê¸°
            recommended_spots = self._rank_spots_with_ai(user_query, all_spots, 20)
            
            # 3. ë°ì´í„° ì •ë¦¬ (ì¤‘ë³µ í•„ë“œ ì œê±°)
            cleaned_spots = [self._clean_spot_data(spot) for spot in recommended_spots[:15]]
            
            return {
                'success': True,
                'analysis': analysis,
                'recommended_spots': cleaned_spots,
                'total_analyzed': len(all_spots)
            }
            
        except Exception as e:
            logger.error(f"Error in recommend_tourism_spots: {e}")
            return {
                'success': False,
                'message': str(e),
                'analysis': {},
                'recommended_spots': []
            }
    
    def _clean_spot_data(self, spot: Dict) -> Dict:
        """ê´€ê´‘ì§€ ë°ì´í„°ì—ì„œ ì¤‘ë³µ í•„ë“œ ì œê±° ë° ì •ë¦¬"""
        # í•„ìš”í•œ í•„ë“œë§Œ ì„ íƒí•˜ì—¬ ê¹”ë”í•œ ì‘ë‹µ ìƒì„±
        cleaned_spot = {
            'id': spot.get('id', spot.get('contentid', '')),
            'title': spot.get('title', ''),
            'category': spot.get('category', ''),
            'addr1': spot.get('addr1', ''),
            'addr2': spot.get('addr2', ''),
            'overview': spot.get('overview', ''),
            'tel': spot.get('tel', ''),
            'homepage': spot.get('homepage', ''),
            'firstimage': spot.get('firstimage', ''),
            'firstimage2': spot.get('firstimage2', ''),
            'latitude': spot.get('latitude', spot.get('mapy', '')),
            'longitude': spot.get('longitude', spot.get('mapx', '')),
            'contentid': spot.get('contentid', ''),
            'contenttypeid': spot.get('contenttypeid', ''),
            'areacode': spot.get('areacode', ''),
            'sigungucode': spot.get('sigungucode', ''),
            'booktour': spot.get('booktour', ''),
            'tags': spot.get('tags', [])
        }
        
        # ë¹ˆ ê°’ ì œê±°
        return {k: v for k, v in cleaned_spot.items() if v is not None and v != ''}
